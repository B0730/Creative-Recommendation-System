## 5. 结果及其说明文档

[TOC]

### 5.0 结果复现任务概述

#### 5.0.1 复现表2：K=20时比较方法的性能评估（RQ1）。

<center>表2：K=20时比较方法的性能评估。Rec是指召回。粗体表示该列中的获胜者。请注意，MACR实现的改进是显著的（p-value<<0.05）</center>

<img src="pics/Table-2.png" alt="Figure-1" style="zoom: 50%;" />

#### 5.0.2 复现图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响（RQ2）

<div><center><img src="pics/Figure-7.png" alt="Figure-1" style="zoom: 60%;" /><br>图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响</center></div>

#### 5.0.3 复现表3：用户分支和项目分支的影响（RQ3）

<center>表3：用户和项目分支对MACR_MF的影响</center>

|                         | HR@20     | Recall@20 | NDCG@20   |
| ----------------------- | --------- | --------- | --------- |
| MACR_MF                 | **0.140** | **0.109** | **0.050** |
| MACR_MF w/o user branch | 0.137     | 0.106     | 0.046     |
| MACR_MF w/o item branch | 0.116     | 0.089     | 0.038     |
| MACR_MF w/o LI          | 0.124     | 0.096     | 0.043     |
| MACR_MF w/o LU          | 0.138     | 0.108     | 0.048     |

#### 5.0.4 复现图8、图9：评价去偏能力，将MACR_MF和MACR_LightGCN与MF和LightGCN进行比较（RQ4）

<div><center><img src="pics/Figure-8.png" alt="Figure-1" style="zoom: 60%;" /><br>图8：LightGCN（MF）和MACR_LightGCN推荐的不同项目组的频率</center></div>

<div><center><img src="pics/Figure-9.png" alt="Figure-1" style="zoom: 60%;" /><br>图9：Adressa上不同商品组的平均商品召回率。</center></div>

#### 5.0.5 复现图10、11：为什么我们的框架有利于推荐中的去偏

<div><center><img src="pics/Figure-10.png" alt="Figure-1" style="zoom: 50%;" /><br>图10：Adressa上不同用户组的平均σ(yu)比较</center></div>

<div><center><img src="pics/Figure-11.png" alt="Figure-1" style="zoom: 50%;" /><br>图11：Adressa上不同项目组的平均σ(yi)比较</center></div>

#### 5.0.6 复现图12：补充实验C.1--不同K的度量

<div><center><img src="pics/Figure-12.png" alt="Figure-1" style="zoom: 50%;" /><br>图12：Adressa数据集上的Top-K推荐性能，通过HR@K, NDCG@K和Recall@K</center></div>

#### 5.0.7 复现表4、表5：补充实验C.2--超参数的影响

<center>表4：α对于MACR_MF的影响</center>

|      | HR@20 | Recall@20 | NDCG@20 |
| ---- | ----- | --------- | ------- |
| 1e-5 | 0.133 | 0.104     | 0.045   |
| 1e-4 | 0.139 | 0.108     | 0.049   |
| 1e-3 | 0.140 | 0.109     | 0.050   |
| 1e-2 | 0.137 | 0.108     | 0.048   |

<center>表5：β对于MACR_MF的影响</center>

|      | HR@20 | Recall@20 | NDCG@20 |
| ---- | ----- | --------- | ------- |
| 1e-5 | 0.139 | 0.108     | 0.049   |
| 1e-4 | 0.139 | 0.109     | 0.049   |
| 1e-3 | 0.140 | 0.109     | 0.050   |
| 1e-2 | 0.139 | 0.108     | 0.049   |

### 5.1 复现表2：K=20时比较方法的性能评估（RQ1）

#### 5.1.1 MF-Adressa

##### 5.1.1.1 指令

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 1 --log_interval 10 --lr 0.001 --train normalbce --test normal

##### 5.1.1.2 结果

（1）运行时间：10分钟，best epoch：339

（2）准确结果：

> addressa dataset best epoch339: hr:0.10526315789473716 ndcg:0.03117746937877148 recall:0.08002735468943604 precision:0.006794258373205733

（3）粗略结果及其与原文的误差：

粗略结果：HR=0.105，Rec=0.080；NDCG=0.031

原文结果：HR=0.111，Rec=0.085；NDCG=0.034

计算误差：HR -0.006；Rec -0.005；NDCG -0.003

最大误差：<0.01

#### 5.1.2 MACR_MF-Adressa

##### 5.1.2.1 指令

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 0 --log_interval 10 --lr 0.001 --check_c 1 --c 40 --train rubibceboth --test rubi --alpha 1e-3 --beta 1e-3 

##### 5.1.2.2 结果

（1）运行时间：10分钟，best epoch：219

（2）准确结果：

> addressa dataset best epoch219: hr:0.13540669856459364 ndcg:0.04844779112025939 recall:0.10691151750960394 precision:0.009425837320574178

（3）粗略结果及其与原文的误差：

粗略结果：HR=0.135，Rec=0.107；NDCG=0.048

原文结果：HR=0.140，Rec=0.109；NDCG=0.050

计算误差：HR -0.005；Rec -0.002；NDCG -0.002

最大误差：<0.01

#### 5.1.3 MACR_MF-Gowalla

##### 5.1.3.1 指令

> python ./macr_mf/train.py --dataset gowalla --batch_size 4096 --cuda 0 --saveID 0 --log_interval 10 --lr 0.001 --check_c 1 --c 40 --train rubibceboth --test rubi --alpha 1e-2 --beta 1e-3

##### 5.1.3.2 结果

（1）运行时间：180分钟，best epoch：349

（2）准确结果：

> gowalla dataset best epoch349: hr:0.2667271784232356 ndcg:0.05738695245085963 recall:0.08371401928767233 precision:0.026637059128630614

（3）粗略结果及其与原文的误差：

粗略结果：HR=0.267；Rec=0.083；NDCG=0.057

原文结果：HR=0.252，Rec=0.077；NDCG=0.050

计算误差：HR +0.015；Rec +0.006；NDCG +0.007

最大误差：<0.02

#### 5.1.4 LightGCN-Adressa

##### 5.1.4.1 指令

> python macr_lightgcn/LightGCN.py --data_path data/ --dataset addressa --verbose 1 --layer_size [64,64] --Ks [20] --loss bce --test normal --epoch 2000 --early_stop 1 --lr 0.001 --batch_size 1024 --gpu_id 1 --log_interval 10

##### 5.1.4.2 结果

（1）运行时间：120分钟，epoch：380

（2）准确结果：

> Epoch 380 [23.5s + 0.5s]: test==[6.83245=6.82665 + 0.00580 + 0.00000], recall=[0.09810], hr=[0.12392], ndcg=[0.04059]
> Early stopping is trigger at step: 10 log:0.12392344325780869

（3）粗略结果及其与原文的误差：

粗略结果：HR=0.124；Rec=0.098；NDCG=0.041

原文结果：HR=0.123，Rec=0.098；NDCG=0.040

计算误差：HR +0.001；Rec +0.000；NDCG +0.001

最大误差：<0.001